java.lang.ref.Finalizer$FinalizerThread.run;java.lang.ref.ReferenceQueue.remove;java.lang.ref.ReferenceQueue.remove;java.lang.Object.wait 82
org.apache.spark.deploy.SparkSubmit.main;org.apache.spark.deploy.SparkSubmit$.main;org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit;org.apache.spark.deploy.SparkSubmit.doSubmit;org.apache.spark.deploy.SparkSubmit.submit;org.apache.spark.deploy.SparkSubmit.doRunMain$1;org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain;org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment;org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies;org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings;org.apache.ivy.core.settings.IvySettings.<init>;org.apache.ivy.core.settings.IvySettings.<init>;java.lang.ClassLoader.loadClass;sun.misc.Launcher$AppClassLoader.loadClass;java.lang.ClassLoader.loadClass;java.net.URLClassLoader.findClass;java.security.AccessController.doPrivileged;java.net.URLClassLoader$1.run;java.net.URLClassLoader$1.run;java.net.URLClassLoader.access$100;java.net.URLClassLoader.defineClass;sun.misc.Resource.getBytes;java.util.zip.InflaterInputStream.read;java.util.zip.ZipFile$ZipFileInflaterInputStream.fill;java.util.zip.ZipFile$ZipFileInputStream.read;java.util.zip.ZipFile.access$1400;java.util.zip.ZipFile.read 1
org.apache.spark.deploy.SparkSubmit.main;org.apache.spark.deploy.SparkSubmit$.main;org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit;org.apache.spark.deploy.SparkSubmit.doSubmit;org.apache.spark.deploy.SparkSubmit.submit;org.apache.spark.deploy.SparkSubmit.doRunMain$1;org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain;org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment;org.apache.spark.deploy.DependencyUtils$.resolveMavenDependencies;org.apache.spark.deploy.SparkSubmitUtils$.buildIvySettings;org.apache.spark.deploy.SparkSubmitUtils$.createRepoResolvers;org.apache.ivy.plugins.resolver.IBiblioResolver.<init>;org.apache.ivy.plugins.resolver.URLResolver.<init>;org.apache.ivy.plugins.resolver.RepositoryResolver.<init>;org.apache.ivy.plugins.resolver.AbstractPatternsBasedResolver.<init>;org.apache.ivy.plugins.resolver.BasicResolver.<init>;org.apache.ivy.util.HostUtil.getLocalHostName;java.net.InetAddress.getLocalHost;java.net.InetAddress.getAddressesFromNameService;java.net.InetAddress$2.lookupAllHostAddr;java.net.Inet6AddressImpl.lookupAllHostAddr 92
org.apache.spark.deploy.SparkSubmit.main;org.apache.spark.deploy.SparkSubmit$.main;org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit;org.apache.spark.deploy.SparkSubmit.doSubmit;org.apache.spark.deploy.SparkSubmit.submit;org.apache.spark.deploy.SparkSubmit.doRunMain$1;org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain;org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment;scala.Option.getOrElse;org.apache.spark.deploy.SparkSubmit$$anonfun$2.apply;org.apache.spark.deploy.SparkSubmit$$anonfun$2.apply;org.apache.spark.deploy.SparkHadoopUtil$.newConfiguration;org.apache.spark.deploy.SparkHadoopUtil$.org$apache$spark$deploy$SparkHadoopUtil$$appendS3AndSparkHadoopConfigurations;org.apache.hadoop.conf.Configuration.set;org.apache.hadoop.conf.Configuration.set;org.apache.hadoop.conf.Configuration.getProps;org.apache.hadoop.conf.Configuration.loadResources;org.apache.hadoop.conf.Configuration.loadResource;org.apache.xerces.jaxp.DocumentBuilderFactoryImpl.newDocumentBuilder;org.apache.xerces.jaxp.DocumentBuilderImpl.<init>;java.lang.ClassLoader.loadClass;sun.misc.Launcher$AppClassLoader.loadClass;java.lang.ClassLoader.loadClass;java.net.URLClassLoader.findClass;java.security.AccessController.doPrivileged;java.net.URLClassLoader$1.run;java.net.URLClassLoader$1.run;java.net.URLClassLoader.access$100;java.net.URLClassLoader.defineClass;java.security.SecureClassLoader.defineClass;java.lang.ClassLoader.defineClass;java.lang.ClassLoader.defineClass1;java.lang.ClassLoader.loadClass;sun.misc.Launcher$AppClassLoader.loadClass;java.lang.ClassLoader.loadClass;java.net.URLClassLoader.findClass;java.security.AccessController.doPrivileged;java.net.URLClassLoader$1.run;java.net.URLClassLoader$1.run;java.net.URLClassLoader.access$100;java.net.URLClassLoader.defineClass;java.security.SecureClassLoader.defineClass;java.lang.ClassLoader.defineClass;java.lang.ClassLoader.defineClass1;java.lang.ClassLoader.loadClass;sun.misc.Launcher$AppClassLoader.loadClass;java.lang.ClassLoader.loadClass;java.net.URLClassLoader.findClass;java.security.AccessController.doPrivileged;java.net.URLClassLoader$1.run;java.net.URLClassLoader$1.run;java.net.URLClassLoader.access$100;java.net.URLClassLoader.defineClass;sun.misc.Resource.getBytes;java.util.zip.InflaterInputStream.read;java.util.zip.ZipFile$ZipFileInflaterInputStream.fill;java.util.zip.ZipFile$ZipFileInputStream.read;java.util.zip.ZipFile.access$1400;java.util.zip.ZipFile.read 1
org.apache.spark.deploy.SparkSubmit.main;org.apache.spark.deploy.SparkSubmit$.main;org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit;org.apache.spark.deploy.SparkSubmit.doSubmit;org.apache.spark.deploy.SparkSubmit.submit;org.apache.spark.deploy.SparkSubmit.doRunMain$1;org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain;org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment;scala.Option.map;org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$3.apply;org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$3.apply;org.apache.spark.deploy.DependencyUtils$.resolveGlobPaths;scala.collection.AbstractTraversable.flatMap;scala.collection.TraversableLike$class.flatMap;scala.collection.mutable.WrappedArray.foreach;scala.collection.IndexedSeqOptimized$class.foreach;scala.collection.TraversableLike$$anonfun$flatMap$1.apply;scala.collection.TraversableLike$$anonfun$flatMap$1.apply;org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2.apply;org.apache.spark.deploy.DependencyUtils$$anonfun$resolveGlobPaths$2.apply;org.apache.spark.deploy.DependencyUtils$.org$apache$spark$deploy$DependencyUtils$$resolveGlobPath;org.apache.hadoop.fs.FileSystem.get;org.apache.hadoop.fs.FileSystem$Cache.get;org.apache.hadoop.fs.FileSystem$Cache$Key.<init>;org.apache.hadoop.fs.FileSystem$Cache$Key.<init>;org.apache.hadoop.security.UserGroupInformation.getCurrentUser;org.apache.hadoop.security.UserGroupInformation.getLoginUser;org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject;org.apache.hadoop.security.UserGroupInformation.ensureInitialized;org.apache.hadoop.security.UserGroupInformation.initialize;org.apache.hadoop.security.Groups.getUserToGroupsMappingService;org.apache.hadoop.security.Groups.<init>;org.apache.hadoop.security.Groups.<init>;org.apache.hadoop.conf.Configuration.getLong;org.apache.hadoop.conf.Configuration.getTrimmed;org.apache.hadoop.conf.Configuration.get;org.apache.hadoop.conf.Configuration.getProps;org.apache.hadoop.conf.Configuration.loadResources;org.apache.hadoop.conf.Configuration.loadResource 1
java.lang.Thread.run;java.util.concurrent.ThreadPoolExecutor$Worker.run;java.util.concurrent.ThreadPoolExecutor.runWorker;org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run;java.util.concurrent.LinkedBlockingQueue.take;java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await;java.util.concurrent.locks.LockSupport.park;sun.misc.Unsafe.park 138
org.apache.spark.deploy.SparkSubmit.main;org.apache.spark.deploy.SparkSubmit$.main;org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit;org.apache.spark.deploy.SparkSubmit.doSubmit;org.apache.spark.deploy.SparkSubmit.submit;org.apache.spark.deploy.SparkSubmit.doRunMain$1;org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain;org.apache.spark.deploy.JavaMainApplication.start;java.lang.reflect.Method.invoke;sun.reflect.DelegatingMethodAccessorImpl.invoke;sun.reflect.NativeMethodAccessorImpl.invoke;sun.reflect.NativeMethodAccessorImpl.invoke0;com.arcadia.notebook.NotebookSpark.main;com.arcadia.notebook.NotebookSpark$.<clinit>;com.arcadia.notebook.NotebookSpark$.<init>;org.apache.spark.sql.SparkSession$Builder.getOrCreate;scala.Option.getOrElse;org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply;org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply;org.apache.spark.SparkContext$.getOrCreate;org.apache.spark.SparkContext.<init>;scala.Option.foreach;org.apache.spark.SparkContext$$anonfun$11.apply;org.apache.spark.SparkContext$$anonfun$11.apply;org.apache.spark.ui.WebUI.bind;org.apache.spark.ui.JettyUtils$.startJettyServer;org.apache.spark.util.Utils$.startServiceOnPort;scala.collection.immutable.Range.foreach$mVc$sp;org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp;org.apache.spark.ui.JettyUtils$$anonfun$7.apply;org.apache.spark.ui.JettyUtils$$anonfun$7.apply;org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$httpConnect$1;org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$newConnector$1;org.spark_project.jetty.util.component.AbstractLifeCycle.start;org.spark_project.jetty.server.ServerConnector.doStart;org.spark_project.jetty.server.AbstractNetworkConnector.doStart;org.spark_project.jetty.server.AbstractConnector.doStart;org.spark_project.jetty.util.component.ContainerLifeCycle.doStart;org.spark_project.jetty.util.component.ContainerLifeCycle.start;org.spark_project.jetty.util.component.AbstractLifeCycle.start;org.spark_project.jetty.io.SelectorManager.doStart;org.spark_project.jetty.io.SelectorManager.newSelector;org.spark_project.jetty.io.ManagedSelector.<init>;org.spark_project.jetty.util.thread.ExecutionStrategy$DefaultExecutionStrategyFactory.newExecutionStrategy;java.lang.ClassLoader.loadClass;sun.misc.Launcher$AppClassLoader.loadClass;java.lang.ClassLoader.loadClass;java.net.URLClassLoader.findClass;java.security.AccessController.doPrivileged;java.net.URLClassLoader$1.run;java.net.URLClassLoader$1.run;java.net.URLClassLoader.access$100;java.net.URLClassLoader.defineClass;java.security.SecureClassLoader.defineClass;java.lang.ClassLoader.defineClass;java.lang.ClassLoader.defineClass1 1
org.apache.spark.deploy.SparkSubmit.main;org.apache.spark.deploy.SparkSubmit$.main;org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit;org.apache.spark.deploy.SparkSubmit.doSubmit;org.apache.spark.deploy.SparkSubmit.submit;org.apache.spark.deploy.SparkSubmit.doRunMain$1;org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain;org.apache.spark.deploy.JavaMainApplication.start;java.lang.reflect.Method.invoke;sun.reflect.DelegatingMethodAccessorImpl.invoke;sun.reflect.NativeMethodAccessorImpl.invoke;sun.reflect.NativeMethodAccessorImpl.invoke0;com.arcadia.notebook.NotebookSpark.main;com.arcadia.notebook.NotebookSpark$.main;scala.reflect.runtime.package$.universe;scala.reflect.runtime.package$.universe$lzycompute;scala.reflect.runtime.JavaUniverse.<init>;scala.reflect.internal.SymbolTable.<init>;java.lang.ClassLoader.loadClass;sun.misc.Launcher$AppClassLoader.loadClass;java.lang.ClassLoader.loadClass;java.net.URLClassLoader.findClass;java.security.AccessController.doPrivileged;java.net.URLClassLoader$1.run;java.net.URLClassLoader$1.run;java.net.URLClassLoader.access$100;java.net.URLClassLoader.defineClass;sun.misc.Resource.getBytes;java.util.zip.InflaterInputStream.read;java.util.zip.Inflater.inflate;java.util.zip.Inflater.inflateBytes 1
org.apache.spark.deploy.SparkSubmit.main;org.apache.spark.deploy.SparkSubmit$.main;org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit;org.apache.spark.deploy.SparkSubmit.doSubmit;org.apache.spark.deploy.SparkSubmit.submit;org.apache.spark.deploy.SparkSubmit.doRunMain$1;org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain;org.apache.spark.deploy.JavaMainApplication.start;java.lang.reflect.Method.invoke;sun.reflect.DelegatingMethodAccessorImpl.invoke;sun.reflect.NativeMethodAccessorImpl.invoke;sun.reflect.NativeMethodAccessorImpl.invoke0;com.arcadia.notebook.NotebookSpark.main;com.arcadia.notebook.NotebookSpark$.main;org.apache.spark.sql.DatasetHolder.toDF;org.apache.spark.sql.Dataset.toDF;scala.collection.immutable.List.map;scala.collection.TraversableLike$class.map;scala.collection.immutable.List.foreach;scala.collection.TraversableLike$$anonfun$map$1.apply;scala.collection.TraversableLike$$anonfun$map$1.apply;org.apache.spark.sql.Dataset$$anonfun$16.apply;org.apache.spark.sql.Dataset$$anonfun$16.apply;java.lang.ClassLoader.loadClass;sun.misc.Launcher$AppClassLoader.loadClass;java.lang.ClassLoader.loadClass;java.net.URLClassLoader.findClass;java.security.AccessController.doPrivileged;java.net.URLClassLoader$1.run;java.net.URLClassLoader$1.run;java.net.URLClassLoader.access$100;java.net.URLClassLoader.defineClass;sun.misc.Resource.getBytes;java.util.zip.InflaterInputStream.read;java.util.zip.ZipFile$ZipFileInflaterInputStream.fill;java.util.zip.ZipFile$ZipFileInputStream.read;java.util.zip.ZipFile.access$1400;java.util.zip.ZipFile.read 1
java.lang.Thread.run;io.netty.util.concurrent.FastThreadLocalRunnable.run;io.netty.util.internal.ThreadExecutorMap$2.run;io.netty.util.concurrent.SingleThreadEventExecutor$4.run;io.netty.channel.nio.NioEventLoop.run;io.netty.channel.nio.NioEventLoop.select;io.netty.channel.nio.SelectedSelectionKeySetSelector.select;sun.nio.ch.SelectorImpl.select;sun.nio.ch.SelectorImpl.lockAndDoSelect;sun.nio.ch.KQueueSelectorImpl.doSelect;sun.nio.ch.KQueueArrayWrapper.poll;sun.nio.ch.KQueueArrayWrapper.kevent0 39
java.lang.Thread.run;java.util.concurrent.ThreadPoolExecutor$Worker.run;java.util.concurrent.ThreadPoolExecutor.runWorker;java.util.concurrent.ThreadPoolExecutor.getTask;java.util.concurrent.SynchronousQueue.poll;java.util.concurrent.SynchronousQueue$TransferStack.transfer;java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill;java.util.concurrent.locks.LockSupport.parkNanos;sun.misc.Unsafe.park 128
java.lang.Thread.run;java.util.concurrent.ThreadPoolExecutor$Worker.run;java.util.concurrent.ThreadPoolExecutor.runWorker;java.util.concurrent.ThreadPoolExecutor.getTask;java.util.concurrent.LinkedBlockingQueue.poll;java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos;java.util.concurrent.locks.LockSupport.parkNanos;sun.misc.Unsafe.park 20
